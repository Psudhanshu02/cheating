import cv2
import numpy as np

def compute_optical_flow(video_path, interval=3):
    # Open the video file
    cap = cv2.VideoCapture(video_path)

    # Get the frames per second (fps) of the video
    fps = cap.get(cv2.CAP_PROP_FPS)

    # Calculate the frame skip (number of frames to skip to get a frame every 3 seconds)
    frame_skip = int(fps * interval)

    # Initialize the previous frame
    ret, prev_frame = cap.read()
    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

    # List to store the optical flow images
    optical_flow_images = []

    frame_count = 0
    while cap.isOpened():
        # Read the next frame
        ret, frame = cap.read()

        if not ret:
            break

        frame_count += 1

        # If the frame count is a multiple of frame_skip, compute the optical flow
        if frame_count % frame_skip == 0:
            # Convert the frame to grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Compute the optical flow
            flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)

            # Convert flow to polar coordinates
            magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])

            # Create HSV image and populate it with the optical flow data
            hsv = np.zeros((gray.shape[0], gray.shape[1], 3), dtype=np.float32)
            hsv[..., 0] = angle * 180 / np.pi / 2
            hsv[..., 1] = 255
            hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)

            # Convert HSV to int32's
            hsv = np.asarray(hsv, dtype= np.float32)
            rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)

            # Append the optical flow image to the list
            optical_flow_images.append(rgb_flow)

            # Update the previous frame
            prev_frame = gray

    # Release the video capture
    cap.release()

    return optical_flow_images





# change dimention
import cv2
import torch
import torch.nn as nn

# Load image
img = cv2.imread("C:/Users/h560858/OneDrive - Honeywell/speed_detecton/vehicle-speed-estimation/1.png")

# Convert the image to PyTorch tensor and add an extra dimension for batch size
img_tensor = torch.from_numpy(img).unsqueeze(0).permute(0, 3, 1, 2).float()

# Create a pointwise convolution to reduce the number of channels
conv1x1 = nn.Conv2d(img_tensor.shape[1], 2, 1)

# Apply the convolution
output = conv1x1(img_tensor)

print(output.shape)

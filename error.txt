CUDA out of memory. Tried to allocate 2.00 MiB. GPU 0 has a total capacity of 15.73 GiB of which 2.56 MiB is free. Process 2083733 has 644.00 MiB memory in use. Including non-PyTorch memory, this process has 15.08 GiB memory in use. Of the allocated memory 14.87 GiB is allocated by PyTorch, and 3.76 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.
import cv2
import numpy as np
import torch

model1 = EfficientNet.from_pretrained(f'efficientnet-b{0}', in_channels=2, num_classes=1)
def compute_optical_flow(video_path, interval=1):
    speed=[]
    # Open the video file
    cap = cv2.VideoCapture(video_path)

    # Get the frames per second (fps) of the video
    fps = cap.get(cv2.CAP_PROP_FPS)

    # Calculate the frame skip (number of frames to skip to get a frame every 3 seconds)
    frame_skip = int(fps * interval)

    # Initialize the previous frame
    ret, prev_frame = cap.read()
    prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

    # List to store the optical flow images
    optical_flow_images = []
    

    frame_count = 0
    while cap.isOpened():
        # Read the next frame
        ret, frame = cap.read()

        if not ret:
            break

        frame_count += 1

        # If the frame count is a multiple of frame_skip, compute the optical flow
        if frame_count % frame_skip == 0:
            # Convert the frame to grayscale
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Compute the optical flow
            flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)

            # Convert flow to polar coordinates
            magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])

            # Create HSV image and populate it with the optical flow data
            hsv = np.zeros((gray.shape[0], gray.shape[1], 3), dtype=np.float32)
            hsv[..., 0] = angle * 180 / np.pi / 2
            hsv[..., 1] = 255
            hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)

            # Convert HSV to int32's
            hsv = np.asarray(hsv, dtype= np.float32)
            
            rgb_flow = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)
            #rgb_flow=torch.from_numpy(rgb_flow)

            #change dimention
            img_tensor = torch.from_numpy(rgb_flow).unsqueeze(0).permute(0, 3, 1, 2).float()

            # Create a pointwise convolution to reduce the number of channels
            conv1x1 = nn.Conv2d(img_tensor.shape[1], 2, 1)

            # Apply the convolution
            output = conv1x1(img_tensor)

            #output=output.cpu().detach().numpy()

            
            state = torch.load('/home/fatninja/Desktop/velocityEstimation/velocity_estimation_pretrained_model/model1.pth')
            model1.load_state_dict(state)
            model1.to('cuda')
            pre=model1(output.to('cuda'))

            
            optical_flow_images.append(pre)
                    
            prev_frame = gray
            torch.cuda.empty_cache()
        

            

    # Release the video capture
    #cap.release()

    return optical_flow_images
